{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# DASCore Training\n",
    "\n",
    "August 14, 2025\n",
    "\n",
    "This notebook shows an example DASCore application: visualizing and processing signals from signals generated by walking and hammer shots.\n",
    "\n",
    "The walking data and sledge hammer shots were collected in Jan. 2025 and Jun. 2025, respectively, at the UNR farm test site.\n",
    "\n",
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/DASDAE/ctemps_tutorial/blob/master/03_application.ipynb\">\n",
    "    <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>  \n",
    "\n",
    "#### Useful links: \n",
    "* [Colab link](https://colab.research.google.com/github/DASDAE/ctemps_tutorial/blob/master/03_application.ipynb)\n",
    "* [DASCore tutorial](https://dascore.org/tutorial/concepts.html)\n",
    "* [UNR farm test site map](https://drive.google.com/file/d/1v6teeDuYw9Mj33izdEsoNkBJ6ZU5I1eI/view?usp=drive_link)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "# First ensure DASCore is installed. If not, install and restart the kernel.\n",
    "try:\n",
    "    import dascore as dc\n",
    "except ImportError:\n",
    "    !pip install dascore\n",
    "    !pip install ipympl\n",
    "    # resetart kernel\n",
    "    import IPython\n",
    "    IPython.Application.instance().kernel.do_shutdown(True) #automatically restarts kernel\n",
    "\n",
    "# need to stick to 3.9 for now as there is a dependency issue with higher versions that we are working on.\n",
    "import matplotlib\n",
    "if matplotlib.__version__ != \"3.9.2\":\n",
    "  !pip install matplotlib==3.9.2 --quiet\n",
    "  import IPython\n",
    "  IPython.Application.instance().kernel.do_shutdown(True) #automatically restarts kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gdown, zipfile\n",
    "import numpy as np\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## Setup\n",
    "First, we create a directory of DAS files to simulate the output of an acquisition. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee819bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paste the *public* Google Drive share URL \n",
    "url = \"https://drive.google.com/file/d/15xMONKL4E00JANze20OW65xBYmPZGmDV/view?usp=sharing\"\n",
    "out = Path(\"ctemps_das_walking.zip\")\n",
    "\n",
    "# If the zip already exists, skip downloading\n",
    "if not out.exists():\n",
    "    # Ensure we save to the expected filename (avoid gdown renaming surprises)\n",
    "    gdown.download(url=url, output=str(out), quiet=False, fuzzy=True)\n",
    "\n",
    "das_dir = Path(\"ctemps_das_walking\")\n",
    "\n",
    "# If the das_dir already exists, skip unzipping\n",
    "if not das_dir.exists():\n",
    "    das_dir.mkdir(exist_ok=True)\n",
    "    with zipfile.ZipFile(out, \"r\") as zf:\n",
    "        zf.extractall(das_dir)\n",
    "    print(f\"Unzipped the downloaded data to: {das_dir.resolve()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## Exploration\n",
    "\n",
    "We initialize a spool on the directory of DAS files and explore a summary of the contents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update will create an index of the contents for fast querying/access\n",
    "spool = dc.spool(das_dir).update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "spool.get_contents()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51af73ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "patch = spool[0]\n",
    "patch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "There are 2 files, each 10 seconds of data. One example file looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "patch.viz.waterfall(scale=0.0001);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1797e1d7",
   "metadata": {},
   "source": [
    "Quickly look at the data in f-k domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e24675",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply transform on all dimensions\n",
    "fk_patch = patch.dft(patch.dims)\n",
    "\n",
    "# We can't plot complex arrays so only plot amplitude\n",
    "ax = fk_patch.abs().viz.waterfall(scale=0.1)\n",
    "\n",
    "# Zoom in around interesting frequencies\n",
    "ax.set_ylim(-500, 500);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d50368",
   "metadata": {},
   "source": [
    "### **Exercise** \n",
    "Use `Patch.select` to remove the channels outside of study area before performing discrete fourier transform to see if that helps to improve the f-k plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835a0708",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "681dfc4a",
   "metadata": {},
   "source": [
    "## Chunk\n",
    "\n",
    "Let's merge the two patches and create a 20-second patch and select the channels we are interested in. Then, visualize the waterfall and spectrogram plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "befb427f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_chunked = spool.chunk(time=None).select(distance=(50, 300))\n",
    "merged_patch = sp_chunked[0].taper(distance=(0.1, 0.1))\n",
    "merged_patch.viz.waterfall(scale=0.001);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e32ab5",
   "metadata": {},
   "source": [
    "The data is in rad/m/s. We can transform it to strain rate by applying a scaler as noted in OptoDAS interrogator's manual.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f320ca6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wave_length = ? # laser wave length (m)\n",
    "# photoelastic = 0.78 # fiber photoelastic effect (as set in Settings, Acquistion tab)\n",
    "# refractive = ? # refractive index (as set in the Measurement Settings)\n",
    "# scaler = wave_length / (4 * np.pi * photoelastic * refractive)\n",
    "\n",
    "# # Now, update the patch\n",
    "# new_data_merged_patch = merged_patch.update(data=merged_patch.data * scaler)\n",
    "# merged_patch = new_data_merged_patch.update_attrs(data_units=\"1 / s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586c1270",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = merged_patch.viz.spectrogram(scale=0.1)\n",
    "ax.set_ylim(5000, 0);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9abbbbd",
   "metadata": {},
   "source": [
    "## Low-pass filter and downsample\n",
    "The data is recorded in 10 kHz. We can low-pass filter and down sample to better see low-frequency features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfac17e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dascore.units import Hz\n",
    "cut_off = 500 # Hz\n",
    "pa_lp = merged_patch.pass_filter(time=(None, cut_off*Hz)).taper(time=(0.1, 0.1))\n",
    "\n",
    "dt = 1/(2*cut_off)\n",
    "step = np.timedelta64(int(round(dt * 1e9)), \"ns\")\n",
    "new_time_ax = np.arange(pa_lp.attrs[\"time_min\"], pa_lp.attrs[\"time_max\"], step)\n",
    "pa_down_sampled = (\n",
    "    pa_lp.interpolate(time=new_time_ax)\n",
    "    .update_coords(time_step=dt)\n",
    ")\n",
    "pa_down_sampled.viz.waterfall(scale=(-2,2));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da94c011",
   "metadata": {},
   "source": [
    "Let's compare the spectogram of data with original size and downsampled data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fde6f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = pa_lp.viz.spectrogram(scale=0.01);\n",
    "ax.set_ylim(1000, 0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c9b42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ax = pa_down_sampled.viz.spectrogram(scale=0.1);\n",
    "ax.set_ylim(500, 0);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96981ecc",
   "metadata": {},
   "source": [
    "Downsample the data even more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584ddc81",
   "metadata": {},
   "outputs": [],
   "source": [
    "cut_off = 100\n",
    "pa_bp = merged_patch.pass_filter(time=(None, cut_off*Hz)).taper(time=(0.1, 0.1))\n",
    "\n",
    "dt = 1/(2*cut_off)\n",
    "step = np.timedelta64(int(round(dt * 1e9)), \"ns\")\n",
    "new_time_ax = np.arange(pa_bp.attrs[\"time_min\"], pa_bp.attrs[\"time_max\"], step)\n",
    "pa_down_sampled = (\n",
    "    pa_bp.interpolate(time=new_time_ax)\n",
    "    .update_coords(time_step=dt)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b29f03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = pa_down_sampled.viz.spectrogram(scale=0.1);\n",
    "ax.set_ylim(100, 0);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fad0b7d",
   "metadata": {},
   "source": [
    "### Exercise \n",
    "Using the `Patch.pass_filter()` funtion, apply a band-pass filter of 1 to 30 Hz. Then, visualize the f-k plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f282decd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "35cffc18",
   "metadata": {},
   "source": [
    "Plot the f-k again for the downsampled data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0062864d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fk_patch = pa_down_sampled.dft(pa_down_sampled.dims)\n",
    "\n",
    "# We can't plot complex arrays so only plot amplitude\n",
    "ax = fk_patch.abs().viz.waterfall(scale=0.1)\n",
    "\n",
    "# Zoom in around interesting frequencies\n",
    "ax.set_ylim(-100, 100);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "## Slope filter\n",
    "\n",
    "Now, after looking at the f-k plot and considering our signal of interest, we apply a slope filter to remove high-velocity signals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14dae9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "v1 = 0.1 # m/s\n",
    "v2 = 20 # m/s\n",
    "filt = np.array([0.1*v1, v1, v2, 10*v2])\n",
    "patch_slope_filtered = pa_down_sampled.slope_filter(filt=filt)\n",
    "patch_slope_filtered.viz.waterfall(scale=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "### **Exercise** \n",
    "Use `Patch.rolling()` [function](https://dascore.org/api/dascore/proc/rolling/rolling.html) to improve denoising the data by applying a moving median over 0.1 second window with 0.5 step. Call it patch_filtered.\n",
    "Finally, visualize and save the patch_filtered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b53c3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8c40073b",
   "metadata": {},
   "source": [
    "## Hammer shots\n",
    "\n",
    "As a final challenge, let's work on the hammer shots data and apply different processing functions to enhance visualization. You can also use DASCore's [Patch.dispersion_phase_shift()](https://dascore.org/api/dascore/transform/dispersion/dispersion_phase_shift.html) funtion to perform dispersion analysis and characterize surface waves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a030ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paste the *public* Google Drive share URL \n",
    "url = \"https://drive.google.com/file/d/1GrfUD5kLDC8Q1v4A7BUCrzalK1HA_HAI/view?usp=drive_link\"\n",
    "out = Path(\"ctemps_das_hammer_shots.zip\")\n",
    "\n",
    "# If the zip already exists, skip downloading\n",
    "if not out.exists():\n",
    "    # Ensure we save to the expected filename (avoid gdown renaming surprises)\n",
    "    gdown.download(url=url, output=str(out), quiet=False, fuzzy=True)\n",
    "\n",
    "das_dir = Path(\"ctemps_das_hammer_shots\")\n",
    "\n",
    "# If the das_dir already exists, skip unzipping\n",
    "if not das_dir.exists():\n",
    "    das_dir.mkdir(exist_ok=True)\n",
    "    with zipfile.ZipFile(out, \"r\") as zf:\n",
    "        zf.extractall(das_dir)\n",
    "    print(f\"Unzipped the downloaded data to: {das_dir.resolve()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902d39b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "spool = dc.spool(das_dir).update()\n",
    "spool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced52366",
   "metadata": {},
   "outputs": [],
   "source": [
    "patch = spool[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dc_user",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
